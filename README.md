# Веб-сервис для классификации тональности текста

В данном репозитории содержится код веб-сервиса на Flask для классификации тональности текста.
У веб-сервиса имеется один метод `/classify`, который обрабатывает POST-запросы и принимает на вход json вида `{"text": "..."}` 
и возвращает в ответ json вида `{"class": label}`, где `label` одно из значений `['negative', 'neutral', 'positive', 'skip', 'speech']`.

Данный веб-сервис может использовать в качестве модели произвольный sklearn estimator (в том числе sklearn.pipeline) или модель, реализованную на Keras, обученные для этой задачи.
Ожидается, что используемая модель в качестве результата классификации возвращает целое число от 0 до 4.
Определено следуюющее соответсвие выходов модели и меток классов: `{0: "negative", 1: "neutral", 2: "positive", 3: "skip", 4: "speech"}`

При сборки контейнера с веб-сервисом в качестве параметра необходимо передать имя директории, в которой содержится сохранённая модель.
В зависимости от расширений файлов в этой директории, веб-приложение пытается инстанцировать ту или иную модель. 
Существуют 3 допустимых конфигурации:

1. В директории имеется один файл с расширением .joblib и ни одного файла с расширением .h5 - из файла с расширением .joblib загружается sklearn estimator, 
у которого в последсвии используется метод 'predict'.
2. В директории имеется один файл с расширением .h5 и ни одного файла с расширением .joblib - из файла с расширением .h5 загружается Keras модель, 
у которой в последсвии используется метод 'predict_class'.
3. В директории имеется один файл с расширением .h5 и один файл с расширением .joblib - из файла с расширением .joblib загружается sklearn transformer, 
который используется для преобразования данных (методом 'transform')
а, из файла с расширением .h5 загружается Keras модель, 
у которой в последствии используется метод 'predict_class'.

Чтобы обученные модели были корректно инстанциированы, в sklearn рекомендутеся использовать сериализацию с помощью 'joblib':
```
from sklearn.externals import joblib
joblib.dump(clf, "clf.joblib"))
```
В Keras нужно сохранять целиком модель, а не только её веса:
```
model.save("model.h5")
```

### Модель определения сентимента

Сравнение random forest на bag-of-words и нейронной сети с эмбеддингами в ноутбуке 'sentiment-model-exploration.ipynb'

В качестве примера модели, в данном репозитории используется нейронная сеть, состоящая из слоя с предобученными эмбеддингами и полносвязного слоя.
Для обучения используется датасет RuSentiment http://text-machine.cs.uml.edu/projects/rusentiment/.
Исходные тексты для этой модели трансформируются в последовательность частотных рангов каждого токена, в расчёт берутся только 10000 наиболее частоупотребимых токенов в обучающей выборки.
Для полученных последовательностей используется паддинг нулевыми значениями.
Процесс трансформации данных сделан в виде sklearn-pipeline, с двумя кастомными трансформерами, реализации которых содержатся в файле `model_runtime/transformers.py`


В скрипте в первых строчках определены переменные-параметры:
* data_dir - путь к директории с файлами датасета RuSentiment (доступны в [репозитории](https://github.com/text-machine-lab/rusentiment))
* embeddings_filename - путь к vec-файлу с распакованными эмбеддингами 
(использовались Vkontakte word embeddings, доступные также на [странице проекта RuSentiment](http://text-machine.cs.uml.edu/projects/rusentiment/)  )
* model_output_dir - имя директории, в которую будут сохранены файлы с параметрами обученной модели


### Сборка Docker-образа

При сборке Docker-образа необходимо передать аргумент model_dir, в котором будет передано имя директории с сохранённой моделью.

Команда для сборки образа:

```
$ docker build -t denis-m-smirnov/sentiment-web-service:1.0 --build-arg model_dir=keras_model .

```

### Запуск контейнера:

```
$ docker run -d -p 5000:5000 --rm denis-m-smirnov/sentiment-web-service:1.0

```